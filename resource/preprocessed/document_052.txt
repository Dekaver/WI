Problem HTTP error 403 in Python 3 Web Scraping - Stack Overflow
Stack Overflow
About
Products
For Teams
Stack Overflow
Public questions & answers
Stack Overflow for Teams
Where developers & technologists share private knowledge with coworkers
Jobs
Programming & related technical career opportunities
Talent
Recruit tech talent & build your employer brand
Advertising
Reach developers & technologists worldwide
About the company
Loading…
Log in
Sign up
current community
Stack Overflow
help
chat
Meta Stack Overflow
your communities
Sign up or log in to customize your list.
more stack exchange communities
company blog
People who code: we want your input.
Take the Survey
Join Stack Overflow to learn, share knowledge, and build your career.
Sign up with email
Sign up
Sign up with Google
Sign up with GitHub
Sign up with Facebook
Home
Public
Questions
Tags
Users
Find a Job
Jobs
Companies
Teams
Stack Overflow for Teams
– Collaborate and share knowledge with a private group.
Create a free Team
What is Teams?
Teams
What’s this?
Create free Team
Teams
Q&A for work
Connect and share knowledge within a single location that is structured and easy to search.
Learn more
Problem HTTP error 403 in Python 3 Web Scraping
Ask Question
Asked
8 years ago
Active
yesterday
Viewed
196k times
123
56
I was trying to scrape a website for practice, but I kept on getting the HTTP Error 403 (does it think I'm a bot)?
Here is my code:
#import requests
import urllib.request
from bs4 import BeautifulSoup
#from urllib import urlopen
import re
webpage = urllib.request.urlopen('http://www.cmegroup.com/trading/products/#sortField=oi&sortAsc=false&venues=3&page=1&cleared=1&group=1').read
findrows = re.compile('<tr class="- banding(?:On|Off)>(.*?)</tr>')
findlink = re.compile('<a href =">(.*)</a>')
row_array = re.findall(findrows, webpage)
links = re.finall(findlink, webpate)
print(len(row_array))
iterator = []
The error I get is:
File "C:\Python33\lib\urllib\request.py", line 160, in urlopen
return opener.open(url, data, timeout)
File "C:\Python33\lib\urllib\request.py", line 479, in open
response = meth(req, response)
File "C:\Python33\lib\urllib\request.py", line 591, in http_response
'http', request, response, code, msg, hdrs)
File "C:\Python33\lib\urllib\request.py", line 517, in error
return self._call_chain(*args)
File "C:\Python33\lib\urllib\request.py", line 451, in _call_chain
result = func(*args)
File "C:\Python33\lib\urllib\request.py", line 599, in http_error_default
raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 403: Forbidden
python http web http-status-code-403
Share
Follow
edited yesterday
barny
5,30344 gold badges1616 silver badges2121 bronze badges
asked May 18 '13 at 17:47
JoshJosh
2,57177 gold badges3333 silver badges5252 bronze badges
0
Add a comment
|
7 Answers
7
Active
Oldest
Votes
260
This is probably because of mod_security or some similar server security feature which blocks known spider/bot user agents (urllib uses something like python urllib/3.3.0, it's easily detected). Try setting a known browser user agent with:
from urllib.request import Request, urlopen
req = Request('http://www.cmegroup.com/trading/products/#sortField=oi&sortAsc=false&venues=3&page=1&cleared=1&group=1', headers={'User-Agent': 'Mozilla/5.0'})
webpage = urlopen(req).read()
This works for me.
By the way, in your code you are missing the () after .read in the urlopen line, but I think that it's a typo.
TIP: since this is exercise, choose a different, non restrictive site. Maybe they are blocking urllib for some reason...
Share
Follow
edited May 18 '13 at 18:06
answered May 18 '13 at 17:52
Stefano SanfilippoStefano Sanfilippo
29.2k77 gold badges7171 silver badges7878 bronze badges
3
I assume it's safe to reuse req for multiple urlopen calls.
– Acumenus
Feb 2 '19 at 0:28
1
It might be little late, but I already have User-Agent in my code, still it gives me Error 404: Access denied
– Reema Parakh
Jul 24 '19 at 4:23
This works but I feel like they must have a good reason to block bots and I'm violating their terms of service
– xjcl
Oct 11 '19 at 7:19
Add a comment
|
47
Definitely it's blocking because of your use of urllib based on the user agent. This same thing is happening to me with OfferUp. You can create a new class called AppURLopener which overrides the user-agent with Mozilla.
import urllib.request
class AppURLopener(urllib.request.FancyURLopener):
version = "Mozilla/5.0"
opener = AppURLopener()
response = opener.open('http://httpbin.org/user-agent')
Source
Share
Follow
answered Aug 1 '15 at 6:00
zetazeta
1,33211 gold badge1818 silver badges1313 bronze badges
7
3
The top answer didn't work for me, while yours did. Thanks a lot!
– Tarun Uday
Mar 31 '16 at 19:32
This works just fine but I need to attach the ssl configuration to this. How do I do this? Before I just added it as a second parameter (urlopen(request,context=ctx))
– Hauke
Apr 25 '17 at 17:40
2
looks like it did open but it says 'ValueError: read of closed file'
– Martian2049
May 11 '17 at 15:37
@zeta How did you manage to scrape OfferUp and provide the requisite geo coordinates to perform the search from a script?
– CJ Travis
Jun 21 '17 at 14:35
@CJTravis , I wasn't scraping OfferUp. I was just retrieving item values based on an exact URL of an item. That didn't require any geo coordinates for me
– zeta
Jun 23 '17 at 8:00
|
Show 2 more comments
18
"This is probably because of mod_security or some similar server security feature which blocks known
spider/bot
user agents (urllib uses something like python urllib/3.3.0, it's easily detected)" - as already mentioned by Stefano Sanfilippo
from urllib.request import Request, urlopen
url="https://stackoverflow.com/search?q=html+error+403"
req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})
web_byte = urlopen(req).read()
webpage = web_byte.decode('utf-8')
The web_byte is a byte object returned by the server and the content type present in webpage is mostly utf-8.
Therefore you need to decode web_byte using decode method.
This solves complete problem while I was having trying to scrape from a website using PyCharm
P.S -> I use python 3.4
Share
Follow
edited yesterday
barny
5,30344 gold badges1616 silver badges2121 bronze badges
answered Dec 25 '17 at 7:57
royatirekroyatirek
1,45811 gold badge1515 silver badges3030 bronze badges
Add a comment
|
4
Based on previous answers this has worked for me with Python 3.7 by increasing the timeout to 10.
from urllib.request import Request, urlopen
req = Request('Url_Link', headers={'User-Agent': 'XYZ/3.0'})
webpage = urlopen(req, timeout=10).read()
print(webpage)
Share
Follow
edited Mar 24 at 11:23
royatirek
1,45811 gold badge1515 silver badges3030 bronze badges
answered Apr 16 '20 at 18:48
Jonny_PJonny_P
4133 bronze badges
Add a comment
|
2
Since the page works in browser and not when calling within python program, it seems that the web app that serves that url recognizes that you request the content not by the browser.
Demonstration:
curl --dump-header r.txt http://www.cmegroup.com/trading/products/#sortField=oi&sortAsc=false&venues=3&page=1&cleared=1&group=1
...
<HTML><HEAD>
<TITLE>Access Denied</TITLE>
</HEAD><BODY>
<H1>Access Denied</H1>
You don't have permission to access ...
</HTML>
and the content in r.txt has status line:
HTTP/1.1 403 Forbidden
Try posting header 'User-Agent' which fakes web client.
NOTE: The page contains Ajax call that creates the table you probably want to parse. You'll need to check the javascript logic of the page or simply using browser debugger (like Firebug / Net tab) to see which url you need to call to get the table's content.
Share
Follow
edited May 18 '13 at 18:00
answered May 18 '13 at 17:55
Robert LujoRobert Lujo
12.9k44 gold badges4646 silver badges6464 bronze badges
Add a comment
|
1
You can try in two ways. The detail is in this link.
1) Via pip
pip install --upgrade certifi
2) If it doesn't work, try to run a Cerificates.command that comes bundled with Python 3.* for Mac:(Go to your python installation location and double click the file)
open /Applications/Python\ 3.*/Install\ Certificates.command
Share
Follow
answered Nov 16 '18 at 3:55
JohnsonJohnson
911 bronze badge
Add a comment
|
1
If you feel guilty about faking the user-agent as Mozilla (comment in the top answer from Stefano), it could work with a non-urllib User-Agent as well. This worked for the sites I reference:
req = urlrequest.Request(link, headers={'User-Agent': 'XYZ/3.0'})
urlrequest.urlopen(req, timeout=10).read()
My application is to test validity by scraping specific links that I refer to, in my articles. Not a generic scraper.
Share
Follow
answered Mar 14 '20 at 3:22
Sudeep PrasadSudeep Prasad
5111 bronze badge
Add a comment
|
Your Answer
Thanks for contributing an answer to Stack Overflow!Please be sure to answer the question. Provide details and share your research!But avoid …Asking for help, clarification, or responding to other answers.Making statements based on opinion; back them up with references or personal experience.To learn more, see our tips on writing great answers.
Draft saved
Draft discarded
Sign up or log in
Sign up using Google
Sign up using Facebook
Sign up using Email and Password
Submit
Post as a guest
Name
Email
Required, but never shown
Post as a guest
Name
Email
Required, but never shown
Post Your Answer
Discard
By clicking “Post Your Answer”, you agree to our terms of service, privacy policy and cookie policy
Not the answer you're looking for? Browse other questions tagged python http web http-status-code-403
or ask your own question.
The Overflow Blog
Using low-code tools to iterate products faster
Podcast 345: A good software tutorial explains the How. A great one explains…
Featured on Meta
Take the 2021 Developer Survey
Linked
2
How to get round the HTTP Error 403: Forbidden with urllib.request using Python 3
3
Python - Scraping with BeautifulSoup and Urllib
3
Python 3, urlopen - HTTP Error 403: Forbidden
2
Using python re.compile with beautiful soup to match a string
2
Python urllib.request.urlopen() returning error 403
0
Urllib HTTP Error 403
-1
HTML parsing forbidden error
0
Webscraping with urllib
0
Python 3 Web Scraping error 403
0
Web scraping issue
See more linked questions
Related
3091
403 Forbidden vs 401 Unauthorized HTTP responses
0
python: urllib2.HTTPError: HTTP Error 405: Method Not Allowed
2
Python 3.5 urllib.request 403 Forbidden Error
1
HTTP Error 404: Not Found python urllib
0
urllib.error.HTTPError: HTTP Error 400: Bad Request
0
Web Scraping - Detective Conan
0
urllib.error.HTTPError: HTTP Error 404: Not found - python
0
How to use pastebin API with python?[specific error]
Hot Network Questions
LaTex error : "Missing } inserted"
are the power connections for BECs of ESCs made in parallel or series with each other?
How to remove the new weather info from the taskbar?
Showing the bounding box for every coordinate system in QGIS
What are the safety and warranty implications of steaming bread in a domestic oven?
Sum of set bits from 1 to n
Can I gain AC efficiency by spraying condensate water on the outdoor coils?
Are there any greater risks of traveling significantly faster to another planet?
Why would a modern city with a warm climate have a skyway system?
How come full throttle is meaning full speed instead of the opposite?
What's the definition of an artifact in regards to a Sphere of Annihilation?
Heating of hydraulic oil with hardtail electric MTB brakes
Is there a threadlocker that requires heat to release and can withstand thousands of heat-cool cycles without needing to be reapplied or deteriorating
What is the right tool for old, rusty, flat cross head bolts?
How to get real-looking rust that will be safe to the touch?
Why some CRS are deprecated in QGIS?
Is maximum speed a thing?
Critical differences between Ubuntu Server and Ubuntu Desktop for 20.04 LTS?
Revisiting the unreasonable effectiveness of mathematics
Find the mean of two values, take two
Telling a coworker they aren't invited into my house
How was it calculated that Dream cheated on his Minecraft v1.16 glitchless speedrun?
Being forced to take annual leave against my wishes, what are my options
Why was the neutrino thought to be massless?
more hot questions
Question feed
Subscribe to RSS
Question feed
To subscribe to this RSS feed, copy and paste this URL into your RSS reader.
lang-py
Stack Overflow
Questions
Jobs
Developer Jobs Directory
Salary Calculator
Help
Mobile
Products
Teams
Talent
Advertising
Enterprise
Company
About
Press
Work Here
Legal
Privacy Policy
Terms of Service
Contact Us
Cookie Settings
Cookie Policy
Stack Exchange Network
Technology
Life / Arts
Culture / Recreation
Science
Other
Stack Overflow
Server Fault
Super User
Web Applications
Ask Ubuntu
Webmasters
Game Development
TeX - LaTeX
Software Engineering
Unix & Linux
Ask Different (Apple)
WordPress Development
Geographic Information Systems
Electrical Engineering
Android Enthusiasts
Information Security
Database Administrators
Drupal Answers
SharePoint
User Experience
Mathematica
Salesforce
ExpressionEngine® Answers
Stack Overflow em Português
Blender
Network Engineering
Cryptography
Code Review
Magento
Software Recommendations
Signal Processing
Emacs
Raspberry Pi
Stack Overflow на русском
Code Golf
Stack Overflow en español
Ethereum
Data Science
Arduino
Bitcoin
Software Quality Assurance & Testing
Sound Design
Windows Phone
more (29)
Photography
Science Fiction & Fantasy
Graphic Design
Movies & TV
Music: Practice & Theory
Worldbuilding
Video Production
Seasoned Advice (cooking)
Home Improvement
Personal Finance & Money
Academia
Law
Physical Fitness
Gardening & Landscaping
Parenting
more (10)
English Language & Usage
Skeptics
Mi Yodeya (Judaism)
Travel
Christianity
English Language Learners
Japanese Language
Chinese Language
French Language
German Language
Biblical Hermeneutics
History
Spanish Language
Islam
Русский язык
Russian Language
Arqade (gaming)
Bicycles
Role-playing Games
Anime & Manga
Puzzling
Motor Vehicle Maintenance & Repair
Board & Card Games
Bricks
Homebrewing
Martial Arts
The Great Outdoors
Poker
Chess
Sports
more (16)
MathOverflow
Mathematics
Cross Validated (stats)
Theoretical Computer Science
Physics
Chemistry
Biology
Computer Science
Philosophy
Linguistics
Psychology & Neuroscience
Computational Science
more (10)
Meta Stack Exchange
Stack Apps
API
Data
Blog
Facebook
Twitter
LinkedIn
Instagram
site design / logo © 2021 Stack Exchange Inc; user contributions licensed under cc by-sa.
rev 2021.6.10.39470
Stack Overflow works best with JavaScript enabled
Your privacy
By clicking “Accept all cookies”, you agree Stack Exchange can store cookies on your device and disclose information in accordance with our Cookie Policy.
Accept all cookies
Customize settings